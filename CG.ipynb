{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c179cffe",
   "metadata": {},
   "source": [
    "# Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9648762d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from itertools import zip_longest\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267044f0",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9b27ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ImageDataset class\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, folder_path, transform=None):\n",
    "        self.file_paths = [\n",
    "            os.path.join(folder_path, file_name) for file_name in os.listdir(folder_path)\n",
    "        ]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.file_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")  # Open the image and convert to RGB\n",
    "        if self.transform:\n",
    "            image = self.transform(image)  # Apply transformations if provided\n",
    "        return image\n",
    "\n",
    "# Define transformation pipeline\n",
    "transform_pipeline = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert PIL Image to Tensor\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "def load_images(folder_path):\n",
    "    dataset = ImageDataset(folder_path, transform=transform_pipeline)\n",
    "    # Added num_workers and pin_memory for better performance\n",
    "    return DataLoader(\n",
    "        dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=True, \n",
    "        num_workers=4,  # Adjust this based on your CPU cores\n",
    "        pin_memory=True  # Speeds up data transfer to GPU if using CUDA\n",
    "    )\n",
    "\n",
    "# Load datasets\n",
    "source = load_images('/home/umang.shikarvar/instaformer/wb_small_airshed/images')  # Give source path\n",
    "target = load_images('/home/umang.shikarvar/instaformer/delhi_ncr_small/images')   # Give target path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc352e2",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d1f299",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, is_downsampling=True, add_activation=True, **kwargs):\n",
    "        super().__init__()\n",
    "        if is_downsampling:\n",
    "            self.conv = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, padding_mode=\"reflect\", **kwargs),\n",
    "                nn.InstanceNorm2d(out_channels),\n",
    "                nn.ReLU(inplace=True) if add_activation else nn.Identity(),\n",
    "            )\n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_channels, out_channels, **kwargs),\n",
    "                nn.InstanceNorm2d(out_channels),\n",
    "                nn.ReLU(inplace=True) if add_activation else nn.Identity(),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            ConvolutionalBlock(channels, channels, add_activation=True, kernel_size=3, padding=1),\n",
    "            ConvolutionalBlock(channels, channels, add_activation=False, kernel_size=3, padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, img_channels, num_features=64, num_residuals=6):\n",
    "        super().__init__()\n",
    "        self.initial_layer = nn.Sequential(\n",
    "            nn.Conv2d(img_channels, num_features, kernel_size=7, stride=1, padding=3, padding_mode=\"reflect\"),\n",
    "            nn.InstanceNorm2d(num_features),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.downsampling_layers = nn.ModuleList([\n",
    "            ConvolutionalBlock(num_features, num_features * 2, is_downsampling=True, kernel_size=3, stride=2, padding=1),\n",
    "            ConvolutionalBlock(num_features * 2, num_features * 4, is_downsampling=True, kernel_size=3, stride=2, padding=1),\n",
    "        ])\n",
    "        self.residual_layers = nn.Sequential(*[ResidualBlock(num_features * 4) for _ in range(num_residuals)])\n",
    "        self.upsampling_layers = nn.ModuleList([\n",
    "            ConvolutionalBlock(num_features * 4, num_features * 2, is_downsampling=False, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            ConvolutionalBlock(num_features * 2, num_features * 1, is_downsampling=False, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "        ])\n",
    "        self.last_layer = nn.Conv2d(num_features, img_channels, kernel_size=7, stride=1, padding=3, padding_mode=\"reflect\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.initial_layer(x)\n",
    "        for layer in self.downsampling_layers:\n",
    "            x = layer(x)\n",
    "        x = self.residual_layers(x)\n",
    "        for layer in self.upsampling_layers:\n",
    "            x = layer(x)\n",
    "        return torch.tanh(self.last_layer(x))\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=3, features=[64, 128, 256, 512]):\n",
    "        super().__init__()\n",
    "        self.initial_layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, features[0], kernel_size=4, stride=2, padding=1, padding_mode=\"reflect\"),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        layers = []\n",
    "        in_channels = features[0]\n",
    "        for feature in features[1:]:\n",
    "            layers.append(\n",
    "                nn.Conv2d(in_channels, feature, kernel_size=4, stride=2 if feature != features[-1] else 1, padding=1, padding_mode=\"reflect\"),\n",
    "            )\n",
    "            layers.append(nn.InstanceNorm2d(feature))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            in_channels = feature\n",
    "        layers.append(nn.Conv2d(in_channels, 1, kernel_size=4, stride=1, padding=1, padding_mode=\"reflect\"))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.initial_layer(x)\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee994b5b",
   "metadata": {},
   "source": [
    "# Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7ed22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "mse_loss = nn.MSELoss()\n",
    "cycle_consistency_loss = lambda real, cycled: torch.mean(torch.abs(real - cycled)) * 10.0\n",
    "identity_loss = lambda real, same: torch.mean(torch.abs(real - same)) * 5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a3bb19",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3540719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device to GPU or CPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 250\n",
    "\n",
    "# Instantiate models\n",
    "generator_g = Generator(img_channels=3).to(device)\n",
    "generator_f = Generator(img_channels=3).to(device)\n",
    "discriminator_x = Discriminator().to(device)\n",
    "discriminator_y = Discriminator().to(device)\n",
    "\n",
    "# Optimizers\n",
    "generator_g_optimizer = optim.Adam(generator_g.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "generator_f_optimizer = optim.Adam(generator_f.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "discriminator_x_optimizer = optim.Adam(discriminator_x.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "discriminator_y_optimizer = optim.Adam(discriminator_y.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "\n",
    "# Learning rate schedulers\n",
    "scheduler_g = optim.lr_scheduler.LambdaLR(generator_g_optimizer, lr_lambda=lambda epoch: 1.0 - max(0, epoch - 100) / 100)\n",
    "scheduler_f = optim.lr_scheduler.LambdaLR(generator_f_optimizer, lr_lambda=lambda epoch: 1.0 - max(0, epoch - 100) / 100)\n",
    "scheduler_dx = optim.lr_scheduler.LambdaLR(discriminator_x_optimizer, lr_lambda=lambda epoch: 1.0 - max(0, epoch - 100) / 100)\n",
    "scheduler_dy = optim.lr_scheduler.LambdaLR(discriminator_y_optimizer, lr_lambda=lambda epoch: 1.0 - max(0, epoch - 100) / 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190839b9",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f89645b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TensorBoard writer\n",
    "writer = SummaryWriter(log_dir='/home/umang.shikarvar/instaformer/CG_logs')\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    g_loss_total, f_loss_total, dx_loss_total, dy_loss_total = 0, 0, 0, 0\n",
    "    cycle_loss_total, identity_loss_total = 0, 0\n",
    "\n",
    "    for real_x_batch, real_y_batch in zip_longest(source, target):\n",
    "        if real_x_batch is None or real_y_batch is None:\n",
    "            continue\n",
    "        real_x, real_y = real_x_batch.to(device), real_y_batch.to(device)\n",
    "\n",
    "        # ------------------------\n",
    "        # Train Generators G and F\n",
    "        # ------------------------\n",
    "        # Identity loss\n",
    "        identity_x = generator_f(real_x)  # F(X) should be X\n",
    "        identity_y = generator_g(real_y)  # G(Y) should be Y\n",
    "        id_loss_x = torch.mean(torch.abs(real_x - identity_x)) * 5.0\n",
    "        id_loss_y = torch.mean(torch.abs(real_y - identity_y)) * 5.0\n",
    "\n",
    "        # Adversarial loss\n",
    "        fake_y = generator_g(real_x)  # G(X)\n",
    "        fake_x = generator_f(real_y)  # F(Y)\n",
    "        adv_loss_g = mse_loss(discriminator_y(fake_y), torch.ones_like(discriminator_y(fake_y)))\n",
    "        adv_loss_f = mse_loss(discriminator_x(fake_x), torch.ones_like(discriminator_x(fake_x)))\n",
    "\n",
    "        # Cycle-consistency loss\n",
    "        cycle_x = generator_f(fake_y)  # F(G(X))\n",
    "        cycle_y = generator_g(fake_x)  # G(F(Y))\n",
    "        cycle_loss_x = torch.mean(torch.abs(real_x - cycle_x)) * 10.0\n",
    "        cycle_loss_y = torch.mean(torch.abs(real_y - cycle_y)) * 10.0\n",
    "\n",
    "        # Combine generator losses\n",
    "        total_g_loss = adv_loss_g + cycle_loss_x + id_loss_y\n",
    "        total_f_loss = adv_loss_f + cycle_loss_y + id_loss_x\n",
    "\n",
    "        generator_g_optimizer.zero_grad()\n",
    "        generator_f_optimizer.zero_grad()\n",
    "        total_g_loss.backward(retain_graph=True)\n",
    "        total_f_loss.backward()\n",
    "        generator_g_optimizer.step()\n",
    "        generator_f_optimizer.step()\n",
    "\n",
    "        # -------------------------\n",
    "        # Train Discriminators X, Y\n",
    "        # -------------------------\n",
    "        # Discriminator loss for X\n",
    "        real_loss_x = mse_loss(discriminator_x(real_x), torch.ones_like(discriminator_x(real_x)))\n",
    "        fake_loss_x = mse_loss(discriminator_x(fake_x.detach()), torch.zeros_like(discriminator_x(fake_x)))\n",
    "        dx_loss = (real_loss_x + fake_loss_x) * 0.5\n",
    "\n",
    "        discriminator_x_optimizer.zero_grad()\n",
    "        dx_loss.backward()\n",
    "        discriminator_x_optimizer.step()\n",
    "\n",
    "        # Discriminator loss for Y\n",
    "        real_loss_y = mse_loss(discriminator_y(real_y), torch.ones_like(discriminator_y(real_y)))\n",
    "        fake_loss_y = mse_loss(discriminator_y(fake_y.detach()), torch.zeros_like(discriminator_y(fake_y)))\n",
    "        dy_loss = (real_loss_y + fake_loss_y) * 0.5\n",
    "\n",
    "        discriminator_y_optimizer.zero_grad()\n",
    "        dy_loss.backward()\n",
    "        discriminator_y_optimizer.step()\n",
    "\n",
    "        # Accumulate losses\n",
    "        g_loss_total += total_g_loss.item()\n",
    "        f_loss_total += total_f_loss.item()\n",
    "        dx_loss_total += dx_loss.item()\n",
    "        dy_loss_total += dy_loss.item()\n",
    "        cycle_loss_total += cycle_loss_x.item() + cycle_loss_y.item()\n",
    "        identity_loss_total += id_loss_x.item() + id_loss_y.item()\n",
    "\n",
    "    scheduler_g.step()\n",
    "    scheduler_f.step()\n",
    "    scheduler_dx.step()\n",
    "    scheduler_dy.step()\n",
    "\n",
    "    # Log losses to TensorBoard\n",
    "    writer.add_scalar('Loss/Generator_G', g_loss_total, epoch + 1)\n",
    "    writer.add_scalar('Loss/Generator_F', f_loss_total, epoch + 1)\n",
    "    writer.add_scalar('Loss/Discriminator_X', dx_loss_total, epoch + 1)\n",
    "    writer.add_scalar('Loss/Discriminator_Y', dy_loss_total, epoch + 1)\n",
    "    writer.add_scalar('Loss/Cycle_Consistency', cycle_loss_total, epoch + 1)\n",
    "    writer.add_scalar('Loss/Identity', identity_loss_total, epoch + 1)\n",
    "\n",
    "    # Print epoch summary\n",
    "    print(\n",
    "        f\"Epoch [{epoch + 1}/{EPOCHS}]: \"\n",
    "        f\"G_loss: {g_loss_total:.4f}, F_loss: {f_loss_total:.4f}, \"\n",
    "        f\"D_X_loss: {dx_loss_total:.4f}, D_Y_loss: {dy_loss_total:.4f}, \"\n",
    "        f\"Cycle_loss: {cycle_loss_total:.4f}, Identity_loss: {identity_loss_total:.4f}\"\n",
    "    )\n",
    "\n",
    "    # Save generated images\n",
    "    if (epoch + 1) % 25 == 0:\n",
    "        torch.save(generator_g.state_dict(), f'/home/umang.shikarvar/instaformer/wb_CG_gen/generator_CG_{epoch+1}.pth')\n",
    "        print(f\"Saved generator_G state at epoch {epoch + 1}\")\n",
    "\n",
    "# Close TensorBoard writer after training completes\n",
    "writer.close()\n",
    "print(\"Training complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
